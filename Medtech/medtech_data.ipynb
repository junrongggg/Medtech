{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bb500c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time \n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0b9ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-957ca0a2bb8b>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path = 'C:/Users/Dreambuilds/Downloads/webdriver/chomedriver.exe')\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(executable_path = 'C:/Users/Dreambuilds/Downloads/webdriver/chomedriver.exe')\n",
    "wait = WebDriverWait(driver, 10) #wait 10s to let webpage load\n",
    "\n",
    "driver.get('https://clinicaltrials.gov/ct2/about-site/crawling') #getting website url\n",
    "driver.maximize_window()\n",
    "time.sleep(1)\n",
    "\n",
    "#creating dict to store data\n",
    "clinical_trial = {}\n",
    "last_date_list = []\n",
    "summary_list = []\n",
    "description_list = []\n",
    "condition_list = []\n",
    "intervention_list = []\n",
    "criteria_list = []\n",
    "gender_list = []\n",
    "age_list = []\n",
    "\n",
    "# each row in first page\n",
    "for x in range(2, 193): #2,193\n",
    "    #each column in first page\n",
    "    for y in range(1,4):\n",
    "        #index for the 5 links in each square\n",
    "        for z in range(1,6):\n",
    "\n",
    "            xpath_1 = '//*[@id=\"body-copy\"]/div[1]/table/tbody/tr[{}]/td[{}]/a[{}]'.format(x,y,z)\n",
    "            page_1 = wait.until(EC.element_to_be_clickable((By.XPATH, xpath_1))) \n",
    "            page_1.click()\n",
    "\n",
    "            try:\n",
    "                #row in second page                                                \n",
    "                for a in range(2,70):\n",
    "                    #column in second page                                       \n",
    "                    for b in range(1,6): \n",
    "                        #index for the 5 links in each square\n",
    "                        for c in range(1,6):\n",
    "\n",
    "                            try:\n",
    "                                xpath_2 = '//*[@id=\"body-copy\"]/table/tbody/tr[{}]/td[{}]/a[{}]'.format(a,b,c)\n",
    "                                trial = wait.until(EC.element_to_be_clickable((By.XPATH, xpath_2)))\n",
    "                                trial.click()\n",
    "\n",
    "                            except:\n",
    "                                driver.quit()\n",
    "\n",
    "                            time.sleep(1) #delay to let page load\n",
    "\n",
    "                            #clicking on 'Tabular view' button\n",
    "                            tabular_view = wait.until(EC.element_to_be_clickable((By.XPATH,'//*[@id=\"tabular\"]/a')))\n",
    "                            tabular_view.click()\n",
    "\n",
    "                            #scrolling page to allow for faster scraping\n",
    "                            for i in range(1, 11):\n",
    "                                driver.execute_script(\"window.scrollBy(0,300)\")\n",
    "                                time.sleep(0.5)\n",
    "\n",
    "                            #getting last updated date\n",
    "                            #checking if header contains \"Last Update Posted Date\"\n",
    "                            last_update_header = wait.until(EC.visibility_of_element_located((By.XPATH, \".//th[contains(text(), 'Last Update Posted Date')]\")))\n",
    "\n",
    "                            last_update = last_update_header.find_element(By.XPATH, \"./following-sibling::td\") #getting td element within the header\n",
    "                            last_date_list.append(last_update.text) #adding the text to the list\n",
    "\n",
    "                            #getting brief summary\n",
    "                            #checking if header contains \"Brief Summary\"\n",
    "                            brief_summary_header = wait.until(EC.visibility_of_element_located((By.XPATH, \".//th[contains(text(), 'Brief Summary')]\")))\n",
    "\n",
    "                            brief_summary = brief_summary_header.find_element(By.XPATH, './following-sibling::td') #getting td element within the header\n",
    "                            summary_list.append(brief_summary.text) #adding the text to the list\n",
    "\n",
    "                            #getting detailed description\n",
    "                            #checking if header contains \"Detailed Description\"\n",
    "                            detail_description_header = wait.until(EC.visibility_of_element_located((By.XPATH, \".//th[contains(text(), 'Detailed Description')]\")))\n",
    "\n",
    "                            detail_description = detail_description_header.find_element(By.XPATH, './following-sibling::td') #getting td element within the header\n",
    "                            description_list.append(detail_description.text) #adding the text to the list\n",
    "\n",
    "                            #Condition of the trial\n",
    "                            # Check if the header contains \"Condition\"\n",
    "                            header = wait.until(EC.visibility_of_element_located((By.XPATH, \".//th[contains(text(), 'Condition')]\")))\n",
    "\n",
    "                            condition = header.find_element(By.XPATH, \"./following-sibling::td\") #getting td element within the header\n",
    "                            condition_list.append(condition.text) #adding the text to the list\n",
    "\n",
    "                            #intervention of trial\n",
    "                            #checking if header contains \"header\"\n",
    "                            intervention_header = wait.until(EC.visibility_of_element_located((By.XPATH, \".//th[contains(text(), 'Intervention')]\")))\n",
    "\n",
    "                            intervention = intervention_header.find_element(By.XPATH, './following-sibling::td') #getting td element within the header\n",
    "                            intervention_list.append(intervention.text) #adding the text to the list\n",
    "\n",
    "\n",
    "                            #Eligibility Criteria\n",
    "                            #checking if header contains \"Eligibility Criteria\"\n",
    "                            criteria_header = wait.until(EC.visibility_of_element_located((By.XPATH, \".//th[contains(text(), 'Eligibility Criteria')]\")))\n",
    "\n",
    "                            criteria = criteria_header.find_element(By.XPATH, './/following-sibling::td') #getting td element within the header\n",
    "                            criteria_list.append(criteria.text) #adding the text to the list\n",
    "\n",
    "                            #Gender\n",
    "                            #checking if header contains \"Sex/Gender\"\n",
    "                            gender_header = wait.until(EC.visibility_of_element_located((By.XPATH, \".//th[contains(text(), 'Sex/Gender')]\")))\n",
    "\n",
    "                            gender = gender_header.find_element(By.XPATH, \".//following-sibling::td\") #getting td element within the header\n",
    "                            gender_list.append(gender.text) #adding the text to the list\n",
    "\n",
    "\n",
    "                            #Age\n",
    "                            #checking if header contains \"Ages\"\n",
    "                            age_header = wait.until(EC.visibility_of_element_located((By.XPATH, \".//th[contains(text(), 'Ages')]\")))\n",
    "\n",
    "                            age = age_header.find_element(By.XPATH, './/following-sibling::td') #getting td element within the header\n",
    "                            age_list.append(age.text) #adding the text to the list\n",
    "\n",
    "                            driver.back() #return to study detail\n",
    "                            time.sleep(1)\n",
    "                            driver.back() #return to previous page\n",
    "\n",
    "            except:\n",
    "                driver.quit() #end program if error faced\n",
    "\n",
    "        \n",
    "                \n",
    "           \n",
    "                \n",
    "#creating the key pairs in the dict\n",
    "clinical_trial[\"Last Updated\"] = last_date_list\n",
    "clinical_trial[\"Summary\"] = summary_list\n",
    "clinical_trial[\"Description\"] = description_list\n",
    "clinical_trial[\"Condition\"] = condition_list\n",
    "clinical_trial[\"Intervention\"] = intervention_list\n",
    "clinical_trial[\"Criteria\"] = criteria_list\n",
    "clinical_trial[\"Gender\"] = gender_list\n",
    "clinical_trial[\"Age\"] = age_list\n",
    "\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f224ecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe of data collected\n",
    "df = pd.DataFrame(clinical_trial) \n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919261ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting dataframe to csv file\n",
    "df.to_csv('C:/Users/Dreambuilds/Downloads/clinical_trial.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
